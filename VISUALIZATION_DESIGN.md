# LLMsKnow Layer Visualization Tool

> Interactive tool for exploring LLM internal representations and probe predictions.
> Based on the paper "LLMs Know More Than They Show" (arXiv:2410.02707)

---

## Quick Start

```bash
# Start both frontend and backend
cd visualization && bash run.sh

# Or start separately:
# Backend: cd visualization/backend && python -m api.app
# Frontend: cd visualization/frontend && npm run dev
```

**URLs:**
- Frontend: http://localhost:5173
- Backend API: http://localhost:8000
- API Docs: http://localhost:8000/docs

---

## Overview

This visualization tool provides an interactive interface for:

1. **Running inference** on questions from datasets or custom input
2. **Visualizing attention patterns** across layers and heads
3. **Logit Lens analysis** - how token predictions evolve through layers
4. **Correctness Evolution** - how the model's internal "correctness belief" changes across layers
5. **Exploring trained probes** at multiple layers (0, 5, 10, 14, 15, 16, 20, 25, 30)

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      FRONTEND (React + Vite)                    â”‚
â”‚                        http://localhost:5173                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   Model     â”‚  â”‚  Dataset    â”‚  â”‚   Sample Browser      â”‚   â”‚
â”‚  â”‚  Selector   â”‚  â”‚  Selector   â”‚  â”‚ (pagination, search)  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                   Inference Panel                        â”‚   â”‚
â”‚  â”‚  - Custom input OR dataset sample                        â”‚   â”‚
â”‚  â”‚  - Run inference with layer + attention extraction       â”‚   â”‚
â”‚  â”‚  - Token display (clickable)                             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                 Visualization Panel                      â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚  â”‚  â”‚ Attention  â”‚ â”‚ Logit Lens â”‚ â”‚ Correctness Evol.  â”‚   â”‚   â”‚
â”‚  â”‚  â”‚   View     â”‚ â”‚    View    â”‚ â”‚       View         â”‚   â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â”‚ HTTP/REST
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     BACKEND (FastAPI)                          â”‚
â”‚                      http://localhost:8000                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Endpoints:                                                     â”‚
â”‚  - /api/models               List supported models              â”‚
â”‚  - /api/datasets             List datasets with samples         â”‚
â”‚  - /api/combinations         Model+dataset availability         â”‚
â”‚  - /api/model/load           Load model to GPU/MPS              â”‚
â”‚  - /api/inference            Run inference + extract layers     â”‚
â”‚  - /api/inference/attention  Get attention patterns             â”‚
â”‚  - /api/inference/logit-lens Logit lens analysis               â”‚
â”‚  - /api/inference/correctness-evolution  Probe across layers   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Core Modules:                                                  â”‚
â”‚  - model_manager.py          Singleton model loader             â”‚
â”‚  - dataset_manager.py        CSV loading with pagination        â”‚
â”‚  - availability_scanner.py   Scans output/ and checkpoints/     â”‚
â”‚  - layer_extractor.py        Hidden state extraction            â”‚
â”‚  - attention_extractor.py    Attention pattern extraction       â”‚
â”‚  - probe_runner.py           Load and run trained probes        â”‚
â”‚  - exact_answer_extractor.py Extract answer tokens              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Existing Codebase (src/)                    â”‚
â”‚  - probing_utils.py  (model loading, tokenization)             â”‚
â”‚  - probe.py          (probe training)                           â”‚
â”‚  - compute_correctness.py (answer matching)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Supported Models

| Model | Layers | Heads | Hidden Size |
|-------|--------|-------|-------------|
| Mistral-7B-Instruct-v0.2 | 32 | 32 | 4096 |
| Mistral-7B-v0.3 | 32 | 32 | 4096 |
| LLaMA-3-8B | 32 | 32 | 4096 |
| LLaMA-3-8B-Instruct | 32 | 32 | 4096 |

---

## Supported Datasets

| Dataset | Category | Question Column | Answer Column |
|---------|----------|-----------------|---------------|
| Movie QA (Train/Test) | Factual | `Question` | `Answer` |
| Answerable Math | Math | `question` | `answer` |
| MNLI (Train/Validation) | NLI | `Question` | `Answer` |
| Winogrande (Train/Test) | Commonsense | `sentence` | `answer` |
| Winobias (Dev/Test) | Bias | `sentence` | `answer` |
| Natural Questions | Factual | `question` | `answer` |

---

## Visualization Modes

### 1. Attention View

Shows where a selected token "looks" in the sequence.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ” Attention Pattern                                       â”‚
â”‚                                                             â”‚
â”‚  Source token: [Dropdown: select token]                     â”‚
â”‚  Layer: [Slider 0-31]   Head: [Dropdown: avg / 0-31]       â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  0: "Who"        â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘  65%          â”‚  â”‚
â”‚  â”‚  1: " directed"  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  32%          â”‚  â”‚
â”‚  â”‚  2: " the"       â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  15%          â”‚  â”‚
â”‚  â”‚  3: " movie"     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘  89%          â”‚  â”‚
â”‚  â”‚  4: " Titanic"   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  95%  â† max  â”‚  â”‚
â”‚  â”‚  5: "?"          â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  8%           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                             â”‚
â”‚  [Click a bar to select that token as source]              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Features:**
- Select source token (which token's attention to visualize)
- Layer slider (0-31)
- Head selector (individual head or average across all heads)
- Bar chart showing attention weights to all tokens
- Click bars to navigate to different source tokens

---

### 2. Logit Lens View

Shows how token predictions evolve through layers.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ”¬ Logit Lens                                              â”‚
â”‚                                                             â”‚
â”‚  Predicting: "Cameron" (position 8)                         â”‚
â”‚  Using hidden state at: "James" (position 7)               â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚ Layer 0             â”‚  â”‚ Layer 15            â”‚          â”‚
â”‚  â”‚ Target: #2451       â”‚  â”‚ Target: #8          â”‚          â”‚
â”‚  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚          â”‚
â”‚  â”‚ #1 "the"    12.3%   â”‚  â”‚ #1 "Cameron" 67.2%  â”‚          â”‚
â”‚  â”‚ #2 "and"     8.1%   â”‚  â”‚ #2 "Smith"   15.4%  â”‚          â”‚
â”‚  â”‚ #3 "James"   5.2%   â”‚  â”‚ #3 "Brown"    8.9%  â”‚          â”‚
â”‚  â”‚ #4 "a"       4.8%   â”‚  â”‚ #4 "Jones"    4.1%  â”‚          â”‚
â”‚  â”‚ #5 "is"      3.2%   â”‚  â”‚ #5 "the"      2.3%  â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                             â”‚
â”‚  (... more layers ...)                                      â”‚
â”‚                                                             â”‚
â”‚  ğŸ’¡ Key insight: The actual token "Cameron" starts as       â”‚
â”‚     #2451 at layer 0 and rises to #1 by layer 15           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Features:**
- Shows top-K predictions at each layer
- Highlights the actual generated token
- Shows target token rank at each layer (watch it rise!)
- Reveals when the model "decides" on its answer

---

### 3. Correctness Evolution View

Shows how the model's internal "belief" about correctness evolves.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ“ˆ Correctness Evolution                                   â”‚
â”‚                                                             â”‚
â”‚  ğŸ¯ Exact Answer Tokens                                     â”‚
â”‚  "James <mark>Cameron</mark> directed the movie."          â”‚
â”‚  Method: LLM extraction | Token positions: 6, 7            â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Expected: James Cameron                               â”‚  â”‚
â”‚  â”‚ Ground Truth: âœ“ Correct                              â”‚  â”‚
â”‚  â”‚ Before Generation: âœ“ 72% at L15, tok 5               â”‚  â”‚
â”‚  â”‚ After Generation: âœ“ 89% at L15, tok 12               â”‚  â”‚
â”‚  â”‚ âœ“ Model's final self-assessment matches reality      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                             â”‚
â”‚  ğŸ“Š Confidence Across Layers                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  100% â”€                              â—â”€â”€â”€â”€â—â”€â”€â”€â”€â—     â”‚  â”‚
â”‚  â”‚       â”‚                      â—â”€â”€â—â”€â”€â”€â”€                â”‚  â”‚
â”‚  â”‚   50% â”œ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€â—â”€â”€â”€â”€                        â”‚  â”‚
â”‚  â”‚       â”‚          â—â”€â”€â—â”€â”€                              â”‚  â”‚
â”‚  â”‚    0% â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶   â”‚  â”‚
â”‚  â”‚        L0   L5  L10  L14 L15 L16 L20 L25 L30         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                             â”‚
â”‚  ğŸ’¡ First confident layer: L16                             â”‚
â”‚  Peak: 92% at L30                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Features:**
- Extracts "exact answer" tokens from generated response
- Runs probes at all available layers (currently 9 layers)
- D3 line chart showing P(correct) evolution
- Highlights first confident layer (>70%)
- Compares probe prediction vs ground truth
- Shows calibration (does model know what it knows?)

---

## User Flow

### Complete Workflow

```
1. SELECT MODEL
   â””â”€> Dropdown shows available models with ready dataset counts
       e.g., "Mistral 7B Instruct (1 ready, 10 partial)"

2. SELECT DATASET  
   â””â”€> Dropdown shows datasets with status
       âœ“ READY = has probe + answers
       âš  PARTIAL = has answers but no probe
       â—‹ NOT_PROCESSED = raw CSV only

3. BROWSE SAMPLES
   â””â”€> Paginated table with search
       Click row to select sample

4. RUN INFERENCE
   â””â”€> Click "â–¶ Run Inference"
       - Model loads if not cached
       - Generates answer
       - Extracts layer representations
       - Extracts attention patterns
       - Runs probes at all available layers

5. EXPLORE VISUALIZATIONS
   â””â”€> Switch between tabs:
       - Attention (layer/head attention patterns)
       - Logit Lens (token prediction evolution)
       - Correctness (probe predictions across layers)
       
       Click tokens to analyze different positions
```

---

## Trained Probes

Currently trained probes for **Mistral-7B-Instruct + Movie QA**:

| Layer | Status | Token Position |
|-------|--------|----------------|
| 0 | âœ… | exact_answer_last_token |
| 5 | âœ… | exact_answer_last_token |
| 10 | âœ… | exact_answer_last_token |
| 14 | âœ… | exact_answer_last_token |
| 15 | âœ… | exact_answer_last_token |
| 16 | âœ… | exact_answer_last_token |
| 20 | âœ… | exact_answer_last_token |
| 25 | âœ… | exact_answer_last_token |
| 30 | âœ… | exact_answer_last_token |

**To train more probes:**
```bash
cd src && export WANDB_MODE=offline
python3 probe.py --model mistralai/Mistral-7B-Instruct-v0.2 \
  --dataset movies --layer 12 --token exact_answer_last_token \
  --probe_at mlp --seeds 42 --save_clf
```

---

## API Endpoints

### Models & Datasets

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/health` | GET | Health check |
| `/api/models` | GET | List supported models with availability |
| `/api/models/{id}/combinations` | GET | Get dataset status for model |
| `/api/datasets` | GET | List all datasets |
| `/api/datasets/{id}/samples` | GET | Get paginated samples (supports `?search=`) |
| `/api/combinations` | GET | All model+dataset combinations |

### Model Management

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/model/status` | GET | Current model status |
| `/api/model/load` | POST | Load model to GPU/MPS |
| `/api/model/unload` | POST | Unload model |

### Inference

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/inference` | POST | Run inference with layer/attention extraction |
| `/api/inference/layers` | GET | Get layer representations from last inference |
| `/api/inference/attention` | GET | Get attention patterns from last inference |
| `/api/inference/logit-lens` | POST | Logit lens analysis for token position |
| `/api/inference/correctness-evolution` | POST | Probe predictions across layers |

---

## File Structure

```
visualization/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ app.py           # FastAPI routes
â”‚   â”‚   â””â”€â”€ schemas.py       # Pydantic models
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ model_manager.py        # Singleton model loader
â”‚   â”‚   â”œâ”€â”€ dataset_manager.py      # CSV pagination/search
â”‚   â”‚   â”œâ”€â”€ availability_scanner.py # Scan output/ and checkpoints/
â”‚   â”‚   â”œâ”€â”€ layer_extractor.py      # Hidden state extraction
â”‚   â”‚   â”œâ”€â”€ attention_extractor.py  # Attention pattern extraction
â”‚   â”‚   â”œâ”€â”€ probe_runner.py         # Load and run probes
â”‚   â”‚   â”œâ”€â”€ exact_answer_extractor.py # Extract answer tokens
â”‚   â”‚   â””â”€â”€ correctness.py          # Correctness computation
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ logging.py       # Centralized logging
â”‚   â”œâ”€â”€ config.py            # Configuration constants
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.tsx          # Main application
â”‚   â”‚   â”œâ”€â”€ store/
â”‚   â”‚   â”‚   â””â”€â”€ useStore.ts  # Zustand state management
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â””â”€â”€ client.ts    # Axios API client
â”‚   â”‚   â””â”€â”€ components/
â”‚   â”‚       â”œâ”€â”€ ModelSelector.tsx
â”‚   â”‚       â”œâ”€â”€ DatasetSelector.tsx
â”‚   â”‚       â”œâ”€â”€ SampleBrowser.tsx
â”‚   â”‚       â”œâ”€â”€ CombinationDetails.tsx
â”‚   â”‚       â”œâ”€â”€ InferencePanel.tsx
â”‚   â”‚       â”œâ”€â”€ TokenDisplay.tsx
â”‚   â”‚       â”œâ”€â”€ VisualizationPanel.tsx
â”‚   â”‚       â”œâ”€â”€ AttentionView.tsx        # D3 attention chart
â”‚   â”‚       â”œâ”€â”€ LogitLensView.tsx        # Logit lens analysis
â”‚   â”‚       â””â”€â”€ CorrectnessEvolutionView.tsx  # D3 correctness chart
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.ts
â”‚
â””â”€â”€ run.sh                   # Start both servers
```

---

## Key Insights from the Paper

The visualization tool helps explore key findings from "LLMs Know More Than They Show":

1. **Internal Correctness Encoding**: LLMs encode whether their answer is correct in their hidden states, even when they express uncertainty externally.

2. **Layer-wise Evolution**: The "correctness signal" typically emerges in middle layers and strengthens through later layers.

3. **Exact Answer Tokens**: Truthfulness information is concentrated in the last tokens of the exact answer (hence `exact_answer_last_token` probe position).

4. **Probe Predictions vs Ground Truth**: The visualization shows whether the model "knows" it's right or wrong, and compares to actual correctness.

---

## Color Scheme

| Element | Color | Usage |
|---------|-------|-------|
| Background | `#0f1419` | Dark theme base |
| Panel | `#1a2332` | Card backgrounds |
| Border | `#38444d` | Panel borders |
| Accent | `#1d9bf0` | Buttons, highlights |
| Correct | `#4CAF50` | Green for correct predictions |
| Incorrect | `#ff4444` | Red for incorrect predictions |
| Warning | `#fbbf24` | Yellow for highlights |
| Text | `#fff` / `#aaa` | Primary/secondary text |

---

## Requirements

### Backend
```
fastapi>=0.100.0
uvicorn>=0.22.0
pandas>=2.0.0
numpy>=1.24.0
torch>=2.0.0
transformers>=4.30.0
scikit-learn>=1.2.0
```

### Frontend
```
react ^18
zustand (state management)
axios (HTTP client)
d3 (visualizations)
vite (build tool)
```

---

## Troubleshooting

### Backend won't start
```bash
# Check if port 8000 is in use
lsof -i :8000 | grep LISTEN

# Kill existing process
lsof -ti:8000 | xargs kill -9
```

### CORS errors
The backend allows origins on ports 5173-5176. If frontend runs on a different port, add it to `config.py` `CORS_ORIGINS`.

### Model loading fails
- Check GPU/MPS memory (Mistral 7B needs ~14GB)
- Try `use_quantization=true` in load request
- Check HuggingFace token for gated models

### No probe predictions
- Ensure probes are trained: `ls checkpoints/clf_*.pkl`
- Check dataset_id matches output_id in probe filenames
- Run probe training if needed (see "Trained Probes" section)

---

## Future Enhancements

- [ ] Comparison mode: side-by-side analysis of two questions
- [ ] Batch analysis: patterns across multiple samples
- [ ] Export visualizations as images/PDFs
- [ ] 3D layer visualization
- [ ] Attention head importance ranking
- [ ] Neuron-level analysis
